![Maintenance](https://img.shields.io/maintenance/yes/2021.svg?color=red&style=plastic)
![GitHub last commit](https://img.shields.io/github/last-commit/tao-bai/attack-and-defense-methods.svg?style=plastic)
[![Awesome](https://awesome.re/badge.svg?style=flat-square)](https://awesome.re)

# bib_adversarial_examples
Literature collection of adversarial examples.

As continuation from this [collection](https://github.com/tao-bai/attack-and-defense-methods).

# Papers

## Surveys
2022
 - `IEEE` [ANOMALOUS INSTANCE DETECTION IN DEEP LEARNING: A SURVEY](https://www.osti.gov/biblio/1631092)

2021
 - `Journal` [https://paperswithcode.com/paper/adversarial-attacks-and-defenses-on-graphs-a](https://link.springer.com/content/pdf/10.1007/s11633-019-1211-x.pdf)
 - [Countering Malicious DeepFakes: Survey, Battleground, and Horizon](https://arxiv.org/pdf/2103.00218.pdf)

2018
 - [Adversarial Examples: Attacks and Defenses for Deep Learning](https://arxiv.org/pdf/1712.07107.pdf), [github](https://github.com/chbrian/awesome-adversarial-examples-dl)
 - [Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](https://github.com/anishathalye/obfuscated-gradients)


## Attacks

2016
 - `CVPR` [DeepFool: a simple and accurate method to fool deep neural networks](https://arxiv.org/abs/1511.04599)

## Defenses

2021
 - `ICML` + code [A General Framework For Detecting Anomalous Inputs to DNN Classifiers](https://github.com/jayaram-r/adversarial-detection)
 - `ICME` [DefakeHop: A Light-Weight High-Performance Deepfake Detector](https://arxiv.org/abs/2103.06929)

2019
 - `CVPR` [Detection based Defense against Adversarial Examples from the Steganalysis Point of View](https://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_Detection_Based_Defense_Against_Adversarial_Examples_From_the_Steganalysis_Point_CVPR_2019_paper.pdf)
 - `NeurIPS`  [Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/pdf/1905.02175.pdf)


## Adversarial Training

2021
 - `NeurIPS` [Do Wider Neural Networks Really Help Adversarial Robustness?](https://openreview.net/forum?id=wxjtOI_8jO)
 - `ICML` [Meta Adversarial Training against Universal Patches](https://openreview.net/forum?id=sePThSlRHr)

## Detection in Image Segmentation

2022
 - `Preprint` [DAAIN: Detection of Anomalous and Adversarial Input using Normalizing Flows](https://github.com/merantix/mxlabs-daain)
 - `Preprint` [Adversarial Examples on Segmentation Models Can be Easy to Transfer](https://arxiv.org/pdf/2111.11368.pdf)

## Datasets

 - https://github.com/MadryLab/constructed-datasets 


## Others

2021
- `CVPR` [Natural Adversarial Examples](https://arxiv.org/abs/1907.07174)
- https://simons.berkeley.edu/sites/default/files/docs/11887/nn-simons-part2.pdf


## Libs
 - [DeepRobust](https://github.com/DSE-MSU/DeepRobust)
 - [Innsight](https://bips-hb.github.io/innsight/)
 - [RobustBench](https://robustbench.github.io/)
 - [AdverTorch](https://github.com/BorealisAI/advertorch)
 - [MadryLab](https://github.com/MadryLab)
 - [Foolbox](https://github.com/bethgelab/foolbox)


## Links

- [Adversarial Machine Learning Reading List](https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html) by [Nicholas Carlini](https://nicholas.carlini.com)
- [A Complete List of All (arXiv) Adversarial Example Papers](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html) by [Nicholas Carlini](https://nicholas.carlini.com) **Stay Tuned** 

